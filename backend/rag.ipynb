{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ldinh16/Downloads/AI-customer-support-/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "from datasets import load_dataset, Dataset\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import tiktoken  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Initialize Pinecone (use correct import if using newer version)\n",
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'ai-customer-support-chatbot-2'\n",
    "\n",
    "if index_name in pc.list_indexes().names():\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "if index_name not in pc.list_indexes():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"dotproduct\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Connect to Pinecone index\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset('wikipedia', '20220301.simple')\n",
    "\n",
    "# Convert to DataFrame for easy cleaning\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "# Remove rows with NaN values\n",
    "df = df.dropna(subset=['id', 'title', 'url', 'text'])\n",
    "\n",
    "dataset = df.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count tokens using tiktoken\n",
    "def count_tokens(text):\n",
    "    encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoder.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "# Function to split text into chunks based on token count\n",
    "def split_into_chunks(text, max_tokens):\n",
    "    encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoder.encode(text)\n",
    "    chunks = [tokens[i:i + max_tokens] for i in range(0, len(tokens), max_tokens)]\n",
    "    return [encoder.decode(chunk) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text, model=\"text-embedding-ada-002\"):\n",
    "    max_tokens = 8192\n",
    "    chunks = split_into_chunks(text, max_tokens)\n",
    "    \n",
    "    embeddings = []\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            response = client.embeddings.create(\n",
    "                input=[chunk],\n",
    "                model=model\n",
    "            )\n",
    "            embedding = response.data[0].embedding  # Adjust this based on actual response format\n",
    "            if embedding:\n",
    "                embeddings.append(embedding)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating embedding for chunk: {e}\")\n",
    "\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_size(metadata):\n",
    "    import json\n",
    "    return sys.getsizeof(json.dumps(metadata))\n",
    "def validate_embeddings(embedding):\n",
    "    return all(value is not None and not isinstance(value, float) or not np.isnan(value) for value in embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_METADATA_SIZE = 40960  # 40KB in bytes\n",
    "\n",
    "# Usage in store_in_pinecone\n",
    "def store_in_pinecone(id, title, url, text):\n",
    "    embeddings = generate_embeddings(text)\n",
    "\n",
    "    for embedding in embeddings:\n",
    "        if not validate_embeddings(embedding):\n",
    "            print(f\"Skipping invalid embedding for id: {id}\")\n",
    "            continue\n",
    "        print(id, embedding)\n",
    "        metadata = {\n",
    "            \"title\": title,\n",
    "            \"url\": url,\n",
    "            'text': text\n",
    "        }\n",
    "        metadata_size = get_metadata_size(metadata)\n",
    "        if metadata_size > MAX_METADATA_SIZE:\n",
    "            print(f\"Skipping entry for id: {id} due to metadata size exceeding limit.\")\n",
    "            continue\n",
    "\n",
    "        # Ensure the embedding matches the expected dimension\n",
    "        if len(embedding) != 1536:\n",
    "            print(f\"Skipping entry for id: {id} due to incorrect embedding dimension.\")\n",
    "            continue\n",
    "        index.upsert(\n",
    "            vectors=[\n",
    "                {\n",
    "                    \"id\": id,\n",
    "                    \"values\": embedding,\n",
    "                    \"metadata\": metadata\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        print(f\"Data stored in Pinecone for id: {id} successfully\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# def process_in_batches(dataset, batch_size=100):\n",
    "#     total_articles = len(dataset)\n",
    "#     num_batches = math.ceil(total_articles / batch_size)\n",
    "    \n",
    "#     for i in range(num_batches):\n",
    "#         start_index = i * batch_size\n",
    "#         end_index = min(start_index + batch_size, total_articles)\n",
    "#         batch = dataset[start_index:end_index]\n",
    "\n",
    "#         for article in batch:\n",
    "#             store_in_pinecone(article['id'], article['title'], article['url'], article['text'])\n",
    "        \n",
    "#         print(f\"Processed batch {i + 1}/{num_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = dataset[:1000]\n",
    "batch2 = dataset[1000:2000]\n",
    "batch3 = dataset[2000:3000]\n",
    "batch4 = dataset[3000:4000]\n",
    "batch5 = dataset[4000:5000]\n",
    "batch6 = dataset[5000:6000]\n",
    "batch7 = dataset[6000:7000]\n",
    "batch8 = dataset[7000:8000]\n",
    "batch9 = dataset[8000:9000]\n",
    "batch10 = dataset[9000:10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 1388}},\n",
      " 'total_vector_count': 1388}\n"
     ]
    }
   ],
   "source": [
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
